description: unilm

target:
  service: amlk8s
  name: itphyperdgx2cl1
  vc: hai2
  # name: a100-8x-wus2
  # vc: quantus


environment:
  image: nvidia/20.09:v7.0.2
  registry: shumingdocker.azurecr.io
  setup:
  - pip install --user -e fairseq/
  - pip install --user -e infinibatch/
  - echo "master_addr:" "$$MASTER_ADDR"
  - echo "master_port:" $$MASTER_PORT
  - echo "node_rank:" $$OMPI_COMM_WORLD_RANK
  username: shumingdocker


code:
  local_dir: $CONFIG_DIR/..

storage:
  msranlp:
    storage_account_name: msranlp
    container_name: unilm


jobs:
  - name: train
    sku: G16
    sku_count: 4
    command:
      # - python -m torch.distributed.launch --nproc_per_node=8 train.py /mnt/unilm/shaohanh/res/vocab
      - python -m torch.distributed.launch --nproc_per_node=16 --nnodes=4 
        --node_rank=$$OMPI_COMM_WORLD_RANK --master_addr="$$MASTER_ADDR" --master_port=$$MASTER_PORT train.py /mnt/msranlp/shumma/data/16g/
        --task pretraining 
        --tokens-per-sample 512 
        --mask-prob 0.15 
        --span-length 3.0 
        --leave-unmasked-prob 0.0 
        --random-token-prob 0.0
        --criterion electra 
        --arch electra_base 
        --share-encoder-input-output-embed
        --required-batch-size-multiple 8
        --spm-model /mnt/msranlp/shumma/data/16g/sentencepiece.bpe.model
        --optimizer adam 
        --adam-betas '(0.9,0.98)' 
        --adam-eps 1e-6 
        --clip-norm 2.0
        --weight-decay 0.01
        --lr-scheduler polynomial_decay 
        --lr 0.0005 
        --warmup-updates 10000 
        --total-num-update 125000
        --max-update 125000
        --max-tokens 8192
        --update-freq 2
        --sample-break-mode complete_doc
        --log-format simple 
        --log-interval 100
        --disable-validation
        --save-interval-updates 5000
        --no-epoch-checkpoints
        --fp16
        --fp16-init-scale 4
        --fp16-scale-window 256
        --min-loss-scale 0.0001
        --seed 1
        --save-dir /mnt/msranlp/shumma/exp/unilm_exp/electra-unilm-moe-full-doc/
        --tensorboard-logdir $${AMLT_OUTPUT_DIR}/tb-logs
        --ddp-backend=no_c10d
        --distributed-no-spawn
        --batch-read-ahead 100000
        --rel-pos-buckets 32
        --max-rel-pos 128
        --task-moe
        --num-experts 2
        --weight 50.0
        --rescale-init

    aml_mpirun:
      communicator: OpenMpi
    submit_args:
      env:
        NCCL_TREE_THRESHOLD: 1000000