description: evaluate_xsum

target:
  service: amlk8s
  #name: v100-8x-scus
  #vc: quantus

environment:
  image: nvidia/20.09:v7.0.2
  registry: shumingdocker.azurecr.io
  setup:
  - ibstat
  - ulimit -n 40960
  - pip install --user -e fairseq/
  - pip install --user -e infinibatch/
  - echo "master_addr:" "$$MASTER_ADDR"
  - echo "master_port:" $$MASTER_PORT
  - echo "node_rank:" $$OMPI_COMM_WORLD_RANK
  username: shumingdocker
  
storage:
  msranlp:
    storage_account_name: msranlp
    container_name: unilm
  output:
    storage_account_name: yangjianunilm
    container_name: unilm

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: $CONFIG_DIR/


jobs:  
- name: evaluate_xsum_mlm
  sku: G1
  sku_count: 1
  aml_mpirun:
    communicator: OpenMpi
  command:
    - bash ./shells/evaluate_xsum.sh /mnt/output/xsum/model/mlm-baseline-1030/checkpoint_1_125000-ft/lr1e-4-bs5120-sd1-ws4000/checkpoint_best.pt
- name: evaluate_xsum_mlm_encoder
  sku: G1
  sku_count: 1
  aml_mpirun:
    communicator: OpenMpi
  command:
    - bash ./shells/evaluate_xsum.sh /mnt/output/xsum/model/mlm-baseline-1030/checkpoint_1_125000-ft/lr1e-4-bs5120-sd1-ws4000-encoder/checkpoint_best.pt
- name: evaluate_xsum_mae
  sku: G1
  sku_count: 1
  aml_mpirun:
    communicator: OpenMpi
  command:
    - bash ./shells/evaluate_xsum.sh /mnt/output/xsum/model/mae-baseline/checkpoint_1_125000-ft/lr1e-4-bs5120-sd1-ws4000/checkpoint_best.pt
- name: evaluate_xsum_mae_encoder
  sku: G1
  sku_count: 1
  aml_mpirun:
    communicator: OpenMpi
  command:
    - bash ./shells/evaluate_xsum.sh /mnt/output/xsum/model/mae-baseline/checkpoint_1_125000-ft/lr1e-4-bs5120-sd1-ws4000-encoder/checkpoint_best.pt