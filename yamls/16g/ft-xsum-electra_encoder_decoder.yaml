description: ft
target:
  service: amlk8s
  #name: a100-8x-wus2
  #vc: quantus
  # name: itpwus2v100cl
  # vc: gcrprojvc1
  name: v100-8x-eus-1
  vc: quantus
  #name: itplabrr1cl1     
  #vc: resrchvc

environment:
  image: nvidia/20.09:v7.0.2
  registry: shumingdocker.azurecr.io
  setup:
  - pip install --user -e fairseq/
  - pip install --user -e infinibatch/
  - python -m nltk.downloader punkt
  - echo "master_addr:" "$$MASTER_ADDR"
  - echo "master_port:" $$MASTER_PORT
  - echo "node_rank:" $$OMPI_COMM_WORLD_RANK
  username: shumingdocker

code:
  local_dir: $CONFIG_DIR/../..

storage:
  msranlp:
    storage_account_name: msranlp
    container_name: unilm
  output:
    storage_account_name: yangjianunilm
    container_name: unilm

search:
  job_template:
    name: ft-{branch}-{ckpt}-bs{batch_size}-lr{lr}-ws{warmup_steps}-sd{seed}
    sku: G4
    sku_count: 1
    command:
    - export PRETRAINED_MODEL_PATH=/mnt/output/PretrainedModels/electra-encoder-decoder/{branch}/{ckpt}.pt
    - export DATA_DIR=/mnt/msranlp/shumma/xsum/binary_data/en-unilm/
    - export OUTPUT_DIR=/mnt/output/xsum/model/electra-encoder-decoder/{branch}/{ckpt}-ft/lr{lr}-bs{batch_size}-sd{seed}-ws{warmup_steps}/
    - bash ./shells/finetune_xsum_electra_encoder_decoder.sh $${PRETRAINED_MODEL_PATH} $${OUTPUT_DIR} electra_encoder_decoder_base {batch_size} {lr} {warmup_steps} {seed}
    - bash ./shells/evaluate_xsum.sh $${OUTPUT_DIR} checkpoint_best.pt
    submit_args:
      env:
        NCCL_DEBUG: INFO
        MKL_NUM_THREADS: 1
        OMP_NUM_THREADS: 1
  type: grid
  max_trials: 500
  params:
    - name: branch
      spec: discrete
      values: ["lr5e-4-bsz2048-ws10000-wd0.01-dw50"]
    - name: ckpt
      spec: discrete
      values: ["checkpoint_1_125000"]
    - name: seed
      spec: discrete
      values: [1]
    - name: lr
      spec: discrete
      values: ["5e-5", "1e-4", "1.5e-4"]
    - name: batch_size
      spec: discrete
      values: [4096]
    - name: warmup_steps
      spec: discrete
      values: [1000]