description: ft
target:
  service: amlk8s
  #name: a100-8x-wus2
  #vc: quantus
  name: itpwus2v100cl
  vc: gcrprojvc1
  #name: v100-8x-eus-1
  #vc: quantus
  #name: itplabrr1cl1     
  #vc: resrchvc
  #name: v100-8x-scus     
  #vc: quantus

environment:
  image: nvidia/20.09:v7.0.2
  registry: shumingdocker.azurecr.io
  setup:
  - pwd
  - ls ~/
  - ls ./
  - ulimit -n 40960
  - pip install --user fairseq/
  - pip install --user infinibatch/
  #- pip install -U git+https://github.com/pltrdy/pyrouge --user 
  #- git clone https://github.com/pltrdy/files2rouge.git && cd files2rouge && echo '/tmp/code/.files2rouge/' | python setup_rouge.py && python setup.py install --user
  #- python -m nltk.downloader all > nltk.log
  - echo "master_addr:" "$$MASTER_ADDR"
  - echo "master_port:" $$MASTER_PORT
  - echo "node_rank:" $$OMPI_COMM_WORLD_RANK
  username: shumingdocker

code:
  local_dir: $CONFIG_DIR/../../../..

storage:
  msranlp:
    storage_account_name: msranlp
    container_name: unilm
  output:
    storage_account_name: yangjianunilm
    container_name: unilm

search:
  job_template:
    name: ft_xnli_translate-train_{lg}-{initialization_strategy}-{branch}-{ckpt}-gpus8-uf{update_freq}-bs{batch_size}-lr{lr}-ws{warmup_steps}-sd{seed}-cn{clip_norm}-wd{weight_decay}
    sku: G8
    sku_count: 1
    command:
    - export PRETRAINED_MODEL_PATH=/mnt/output/PretrainedModels/multilingual/electra-encoder-decoder-v6/{branch}/{ckpt}.pt
    - export DATA_DIR=/mnt/output/XNLI-XLMR/data-bin/
    - export OUTPUT_DIR=/mnt/output/XNLI-XLMR/model/translate-train/{lg}/v6/{branch}/{ckpt}-ft/lr{lr}-uf{update_freq}-bs{batch_size}-sd{seed}-ws{warmup_steps}-cn{clip_norm}-wd{weight_decay}/{initialization_strategy}/
    - bash ./shells/classification/xnli/translate-train/ft_xnli_our.sh $${DATA_DIR} $${PRETRAINED_MODEL_PATH} $${OUTPUT_DIR} electra_encoder_decoder_v6_base {update_freq} {batch_size} {lr} {warmup_steps} {seed} {max_epoch} {clip_norm} {weight_decay} {max_positions} {initialization_strategy} {split} {lg}
    #- python ./scripts/average_checkpoints.py --inputs $${OUTPUT_DIR} --num-epoch-checkpoints=5 --checkpoint-upper-bound=10  --output $${OUTPUT_DIR}/avg6_10.pt
    #- python ./scripts/average_checkpoints.py --inputs $${OUTPUT_DIR} --num-epoch-checkpoints=5 --checkpoint-upper-bound=15  --output $${OUTPUT_DIR}/avg11_15.pt
    #- python ./scripts/average_checkpoints.py --inputs $${OUTPUT_DIR} --num-epoch-checkpoints=5 --checkpoint-upper-bound=20  --output $${OUTPUT_DIR}/avg16_20.pt
    #- python ./scripts/average_checkpoints.py --inputs $${OUTPUT_DIR} --num-epoch-checkpoints=5 --checkpoint-upper-bound=25  --output $${OUTPUT_DIR}/avg21_25.pt
    #- bash ./shells/classification/xnli/translate-train/evaluate_xnli.sh $${OUTPUT_DIR} avg21_25.pt 16 {split} {lg}
    submit_args:
      env:
        NCCL_DEBUG: INFO
        MKL_NUM_THREADS: 1
        OMP_NUM_THREADS: 1
  type: grid
  max_trials: 500
  params:
    - name: branch
      spec: discrete
      values: ["lr3e-4-bsz8192-ws10000-wd0.05-dw10_-1_-1-iw1.0_-1_-1-g12d4"]
    - name: ckpt
      spec: discrete
      values: ["avg450000_500000"]
    - name: seed
      spec: discrete
      values: [1]
    - name: lr
      spec: discrete
      values: ["5e-5"]
    - name: update_freq
      spec: discrete
      values: [1]
    - name: batch_size
      spec: discrete
      values: [16]
    - name: max_epoch
      spec: discrete
      values: [8]
    - name: warmup_steps
      spec: discrete
      values: [4000]
    - name: initialization_strategy
      spec: discrete
      values: ["discriminator","generator"]
    - name: clip_norm
      spec: discrete
      values: [0.0]
    - name: weight_decay
      spec: discrete
      values: [0.1]
    - name: max_positions
      spec: discrete
      values: [512]
    - name: split
      spec: discrete
      values: ["test"]
    - name: lg
      spec: discrete
      #values: ["en"]
      values: ['en', 'fr', 'es', 'de', 'el', 'bg', 'ru', 'tr', 'ar', 'vi', 'th', 'zh', 'hi', 'sw', 'ur']