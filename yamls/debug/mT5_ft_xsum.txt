/home/v-jiaya/unilm-moe/data/mT5/wikilingual/download-split/data-bin/
--task
seq2seq_generation
--finetune-from-model
/home/v-jiaya/unilm-moe/data/PretrainedModels/mT5/mt5-base/pytorch_model.bin
--max-tokens
1024
--max-sentences
1
--tensorboard-logdir
/home/v-jiaya/unilm-moe/data/wikilingual/model/debug/tb-log/
--log-file
/home/v-jiaya/unilm-moe/data/wikilingual/model/debug/train_log.txt
--max-source-positions
16
--max-target-positions
16
--share-all-embeddings
--arch
mT5
--criterion
label_smoothed_cross_entropy
--label-smoothing
0.1
--weight-decay
0.01
--optimizer
adam
--adam-betas
"(0.9,0.98)"
--adam-eps
1e-08
--clip-norm
1.0
--lr-scheduler
inverse_sqrt
--lr
1e-4
--warmup-updates
4000
--update-freq
1
--skip-invalid-size-inputs-valid-test
--find-unused-parameters
--best-checkpoint-metric
loss
--max-update
1000000
--max-epoch
100
--seed
1
--save-dir
/home/v-jiaya/unilm-moe/data/wikilingual/model/debug/
--no-progress-bar
--log-interval
1
--save-interval-updates
100000
--start-save-epoch
10000
--fp16
--fp16-init-scale
4
--ddp-backend=no_c10d
--debug